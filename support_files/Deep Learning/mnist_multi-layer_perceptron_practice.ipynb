{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Multi-Layer Perceptron - Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic - MNIST Dataset - Part I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 - Import Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Tensor Flow\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Import Dataset of handwritten numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import dataset from example tutorials\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Create a temporary file for the data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indentify the tensorflow object type for the image array\n",
    "\n",
    "type(mnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Explore image datasets data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the trained images arrayu\n",
    "\n",
    "mnist.train.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the data type of the trained image array\n",
    "\n",
    "type(mnist.train.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the shape of the trained image array\n",
    "\n",
    "## Note: Displays 55000 rows with 784 features\n",
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a sample from the array to review the content\n",
    "\n",
    "mnist.train.images[5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.23137257, 0.6392157 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "        0.7607844 , 0.43921572, 0.07058824, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.01568628, 0.5176471 ,\n",
       "        0.93725497, 0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 ,\n",
       "        0.9960785 , 0.9921569 , 0.627451  , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.5372549 , 0.9921569 ,\n",
       "        0.9960785 , 0.9921569 , 0.9921569 , 0.9921569 , 0.75294125,\n",
       "        0.9960785 , 0.9921569 , 0.8980393 , 0.0509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.01568628, 0.5372549 , 0.9843138 , 0.9921569 ,\n",
       "        0.9568628 , 0.50980395, 0.19215688, 0.07450981, 0.01960784,\n",
       "        0.6392157 , 0.9921569 , 0.8235295 , 0.03529412, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.37254903, 0.9921569 , 0.9921569 , 0.8431373 ,\n",
       "        0.1764706 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.6117647 , 0.9921569 , 0.68235296, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.8431373 , 0.9960785 , 0.8117648 , 0.09019608,\n",
       "        0.        , 0.        , 0.        , 0.03921569, 0.3803922 ,\n",
       "        0.85098046, 0.9176471 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.83921576, 0.9921569 , 0.2784314 , 0.        ,\n",
       "        0.        , 0.00784314, 0.19607845, 0.8352942 , 0.9921569 ,\n",
       "        0.9960785 , 0.7058824 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.83921576, 0.9921569 , 0.19215688, 0.        ,\n",
       "        0.        , 0.19607845, 0.9921569 , 0.9921569 , 0.9921569 ,\n",
       "        0.7176471 , 0.04705883, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.7803922 , 0.9921569 , 0.95294124, 0.7686275 ,\n",
       "        0.62352943, 0.95294124, 0.9921569 , 0.9686275 , 0.5411765 ,\n",
       "        0.03137255, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.16470589, 0.9921569 , 0.9921569 , 0.9921569 ,\n",
       "        0.9960785 , 0.9921569 , 0.9921569 , 0.39607847, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.23137257, 0.58431375, 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "        1.        , 0.9960785 , 0.6862745 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.13333334, 0.75294125,\n",
       "        0.9960785 , 0.9921569 , 0.9921569 , 0.9921569 , 0.7843138 ,\n",
       "        0.53333336, 0.89019614, 0.9450981 , 0.27058825, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.33333334, 0.9686275 , 0.9921569 ,\n",
       "        0.9960785 , 0.9921569 , 0.77647066, 0.48235297, 0.07058824,\n",
       "        0.        , 0.19607845, 0.9921569 , 0.8352942 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.2784314 , 0.9686275 , 0.9921569 , 0.9294118 ,\n",
       "        0.75294125, 0.2784314 , 0.02352941, 0.        , 0.        ,\n",
       "        0.        , 0.00784314, 0.5019608 , 0.9803922 , 0.21176472,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.46274513, 0.9921569 , 0.8705883 , 0.14117648,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.03137255, 0.7176471 , 0.9921569 , 0.227451  ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.46274513, 0.9960785 , 0.54509807, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.05490196, 0.7294118 , 0.9960785 , 0.9960785 , 0.227451  ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.2784314 , 0.9686275 , 0.9686275 , 0.54509807,\n",
       "        0.0627451 , 0.        , 0.        , 0.07450981, 0.227451  ,\n",
       "        0.87843144, 0.9921569 , 0.9921569 , 0.8313726 , 0.03529412,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.42352945, 0.9921569 , 0.9921569 ,\n",
       "        0.92549026, 0.6862745 , 0.6862745 , 0.9686275 , 0.9921569 ,\n",
       "        0.9960785 , 0.9921569 , 0.77647066, 0.16862746, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.2627451 , 0.8352942 , 0.8980393 ,\n",
       "        0.9960785 , 0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 ,\n",
       "        0.83921576, 0.48627454, 0.02352941, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.09019608,\n",
       "        0.60784316, 0.60784316, 0.8745099 , 0.7843138 , 0.46274513,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape the sample to display the actual image elements\n",
    "\n",
    "sample = mnist.train.images[5].reshape(28,28)\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - Visualize the image data with matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a30c946a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2d6c1b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the two-dimensional image with .imshow() method\n",
    "\n",
    "plt.imshow(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a30d7b978>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2d86a208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the two-dimensional image with .imshow() method\n",
    "# cmap -> alters the color of the image\n",
    "\n",
    "plt.imshow(sample, cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 4 - Defining Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the (3) parameters for training\n",
    "\n",
    "## Note:\n",
    "# learning_rate -> this is how quickly we adjust the cost function (i.e. cost function \n",
    "# might be the sum of squared errors over your training set)\n",
    "# training_epochs -> this is how many training cycles we go through\n",
    "# batch_size -> this is the size of the batch training data\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define Network Paramters\n",
    "\n",
    "## Note: This decides what the neural network will look like\n",
    "# n_classes -> number of classes; we have written numbers 0 to 9 in the dataset, so this is 10\n",
    "# n_samples -> number of samples in the dataset\n",
    "# n_input -> the expected inputs; we have a 28 x 28 image that flattens to 784 in this example\n",
    "# n_hidden_1/ _2 -> the number of neurons in the hidden layers (i.e. common to use 256 for images)\n",
    "\n",
    "\n",
    "n_classes = 10\n",
    "n_samples = mnist.train.num_examples\n",
    "n_input = 784\n",
    "n_hidden_1 = 256\n",
    "n_hidden_2 = 256\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 5 - Create Functions for Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create multi-layer perceptron function\n",
    "\n",
    "## Note:\n",
    "# Function takes (3) arguments\n",
    "# x -> data inputs\n",
    "# weights -> random normally distributed values based on required data shape\n",
    "# bias -> random normally distributed values based on required data shape\n",
    "\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    '''\n",
    "    x: Placeholder for Data Input\n",
    "    weights: Dict of weights\n",
    "    biases: dict of bias values\n",
    "    '''\n",
    "    \n",
    "    # First Hidden Layer with RELU Activation\n",
    "    # (X * W + B) -> (x = data) multiplied by (W = Weights randomly selected), then added by (B = Bias)\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']),biases['b1'])\n",
    "    \n",
    "    # Function(X * W + B) = RELU is our function -> f(x) = max(0,x) --> This is the activation part\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    \n",
    "    # Second Hidden Layer with RELU Activation\n",
    "    # (X * W + B) -> (x = data) multiplied by (W = Weights randomly selected), then added by (B = Bias)\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    \n",
    "    # Function(X * W + B) = RELU is our function -> f(x) = max(0,x) --> This is the activation part\n",
    "    layer_2 = tf.nn.relu(layer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Weights Dictionary\n",
    "\n",
    "## Note: Remember the flow from input -> to hidden layer -> to output\n",
    "# tf.Variable -> allows us to be aware of state\n",
    "# tf.random_normal -> allows us to generate normally distributed values for a given matrix shape\n",
    "# n_classes -> allows us to create a matrix identifying the value\n",
    "\n",
    "## example output => [0,0,0,1,0,0,0,0,0,0] -> this would mean the output guess is 3\n",
    "\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create Bias Dictionary\n",
    "\n",
    "## Note: Remember the flow from input -> to hidden layer -> to output\n",
    "# tf.Variable -> allows us to be aware of state\n",
    "# tf.random_normal -> allows us to generate normally distributed values for a given matrix shape\n",
    "# n_classes -> allows us to create a matrix identifying the value\n",
    "\n",
    "## example output => [0,0,0,1,0,0,0,0,0,0] -> this would mean the output guess is 3\n",
    "\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create two (2) placeholders for the x and y variables\n",
    "\n",
    "x = tf.placeholder('float', [None,n_input])\n",
    "\n",
    "y = tf.placeholder('float', [None, n_classes])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 - Set the perceptron function and create the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model with perceptron function\n",
    "\n",
    "pred = multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7 - Define cost and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Both labels and logits must be provided.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-139f2fc26016>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define the cost to review errors with model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m               instructions)\n\u001b[0;32m--> 136\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    138\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36msoftmax_cross_entropy_with_logits\u001b[0;34m(_sentinel, labels, logits, dim, name)\u001b[0m\n\u001b[1;32m   1876\u001b[0m   \"\"\"\n\u001b[1;32m   1877\u001b[0m   _ensure_xent_args(\"softmax_cross_entropy_with_logits\", _sentinel,\n\u001b[0;32m-> 1878\u001b[0;31m                     labels, logits)\n\u001b[0m\u001b[1;32m   1879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1880\u001b[0m   with ops.name_scope(\n",
      "\u001b[0;32m~/anaconda/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_ensure_xent_args\u001b[0;34m(name, sentinel, labels, logits)\u001b[0m\n\u001b[1;32m   1713\u001b[0m                      \"named arguments (labels=..., logits=..., ...)\" % name)\n\u001b[1;32m   1714\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1715\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Both labels and logits must be provided.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Both labels and logits must be provided."
     ]
    }
   ],
   "source": [
    "# Define the cost to review errors with model\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred,y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Topic -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Topic -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Step 1 -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Step 1 -"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
